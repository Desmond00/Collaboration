{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pimaIndiansDiabetes.csv')\n",
    "#It can be found here https://www.kaggle.com/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(df.drop('1', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledFeatures = scaler.transform(df.drop('1', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatures = pd.DataFrame(scaledFeatures, columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfFeatures\n",
    "y = df['1']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print ('\\n')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorRate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    predictionSamples = knn.predict(X_test)\n",
    "    errorRate.append(np.mean(predictionSamples != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,40), errorRate, color='blue', linestyle='dashed', marker='o',\n",
    "     markerfacecolor='red', markersize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = timeit.default_timer()\n",
    "knn = KNeighborsClassifier(n_neighbors= 30)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "elapsedTime = timeit.default_timer() - startTime\n",
    "print(\"elapsed time : \",elapsedTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print ('\\n')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TILL THIS ONLY KNN IS USED WHICH IS PROVIDING 96% ACCURACY WITH COMPUTATION TIME OF 0.0124'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NOW FROM HERE WE HAVE PASSED THE WHOLE DATA TO OUR SCA ALGORITHM '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "#SCA IMPLEMENTATION\n",
    "#begin\n",
    "totalFeatures = len(data.columns[:-1])\n",
    "a = 1\n",
    "r1 = a\n",
    "t = 0\n",
    "subsets = []    \n",
    "trainedFeatures = []\n",
    "#SETTING RANDOM SEED FOR REPRODUCABLE RESULTS\n",
    "random.seed(14)\n",
    "#Randomly initialization of each search agents in the population X(t = 1,2,...,m)\n",
    "subsets.append(random.sample(range(1,totalFeatures),int(totalFeatures/3)))#initializing first random subset\n",
    "lowestError = 100 #initializing as highest errorRate for comparison purpose\n",
    "\n",
    "\n",
    "#Function for checking the new generated subset tempSet is already present in the already initialized subsets or not\n",
    "def isRepeat(presentSubsets, newSubset):\n",
    "    #print(subsets)\n",
    "    #print(tempSet)\n",
    "    newSubset.sort()\n",
    "    for subset in presentSubsets:\n",
    "        subset.sort()\n",
    "        if(subset[:] == newSubset[:]):\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "#for generating random search agents in the population   \n",
    "def randomSearchAgents(m, n):\n",
    "    i = 1\n",
    "    while i<m:\n",
    "        X = random.sample(range(1,totalFeatures),n)\n",
    "        if (isRepeat(subsets, X) == False):\n",
    "            subsets.append(X)\n",
    "            i += 1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "#EQUATION 1\n",
    "def updateUsingSineCosine(X):\n",
    "    featureSubset = []\n",
    "    for j in range(len(X)):\n",
    "        #print(X[j])\n",
    "#         if(s%2 == 0):\n",
    "        feature = int(X[j] + r1*math.sin(r2)*abs(r3*P[j]-X[j]))\n",
    "#         else:\n",
    "#             feature = int(X[j] + r1*math.cos(r2)*abs(r3*P[j]-X[j]))\n",
    "        feature %= totalFeatures\n",
    "        featureSubset.append(feature)\n",
    "    return featureSubset\n",
    "\n",
    "\n",
    "#FOR CHECKING THE SCORE FOR EACH SELECTED FEATURE SUBSET\n",
    "def trainTestScore(X, y):\n",
    "    X.head()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "    startTime = timeit.default_timer()\n",
    "    knn = KNeighborsClassifier(n_neighbors = 17)\n",
    "    knn.fit(X_train, y_train)\n",
    "    prediction = knn.predict(X_test)\n",
    "    elapsedTime = timeit.default_timer() - startTime\n",
    "#     print(\"time taken : \",elapsedTime)\n",
    "    error = np.mean(prediction != y_test)\n",
    "    errorRate.append(error)\n",
    "    return error\n",
    "\n",
    "#here subsets list contains the list of randomly initialized search agent indices\n",
    "\n",
    "#INITIALIZE the max numbers of iteration Tmax, we can take it as the total number of columns present\n",
    "Tmax = totalFeatures\n",
    "P = []\n",
    "\n",
    "'''randomly initialize feature subsets, parameter1 denotes total number of feature subsets, here taken as total no of feature avaiable\n",
    "and parameter 2 denotes number of features in each subsets, here we are considering one third of the total number of features'''\n",
    "\n",
    "randomSearchAgents(totalFeatures, int(totalFeatures/3))\n",
    "\n",
    "print(\"randomly initialized subsets: \",subsets)\n",
    "\n",
    "trainedFeatures = subsets[:]\n",
    "\n",
    "\n",
    "\n",
    "while t<Tmax:\n",
    "    #foreach search agent Xi in the population do\n",
    "    '''NOVEL \n",
    "        here the feature subsets generated by randomSearchAgents method are not repeatative, \n",
    "        if any randomly generated feature subset is already present in the previous generated \n",
    "        ones then it is neglected and a new feature subset is generated randomly and checked again.\n",
    "        This process continues until required number of feature subsets are generated which are all unique\n",
    "    NOVEL'''\n",
    "    for subset in subsets:\n",
    "        #Evaluate Xi via the fitness function. if f(Xi)\n",
    "        if(t > 0):\n",
    "            if(isRepeat(trainedFeatures, subset) == False):\n",
    "                trainedFeatures.append(subset)\n",
    "                #print(trainedFeatures)\n",
    "#                 print('new feature : ',subset, \"t=\",t)\n",
    "#             else:\n",
    "#                 print(\"repeat\")\n",
    "        error = trainTestScore(data.iloc[:,subset], df['1'])\n",
    "#       print(\"subset : \",subset,\" error : \",error, \" lowest error : \", lowestError)\n",
    "        #if f(Xi) better than f(P) then\n",
    "        #Set P = Xi;\n",
    "        if (error < lowestError):\n",
    "            P = subset\n",
    "            lowestError = error\n",
    "\n",
    "    #Update r1 using equation 2\n",
    "\n",
    "    r1 = a - t*(a/Tmax)#equation 2\n",
    "\n",
    "    #Generate randomly new values for r2, r3 and s.\n",
    "\n",
    "    r2 = random.uniform(0.1, 1.0)\n",
    "    r3 = random.uniform(0.1, 1.0)\n",
    "#   print('\\n\\n r2:',r2,' r3:',r3,' r1:',r1)\n",
    "    #foreach search agent Xi in the population do\n",
    "    #Update Xi using equation 1.\n",
    "    for i in range(len(subsets)):\n",
    "        subsets[i] = updateUsingSineCosine(subsets[i])\n",
    "#     print(subsets)\n",
    "#     print(P)\n",
    "    t += 1\n",
    "#Return P best solution obtained so far.\n",
    "print(\"best solution: \",P)\n",
    "print(lowestError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,P], df['TARGET CLASS'], test_size = 0.33, random_state = 42)\n",
    "startTime = timeit.default_timer()\n",
    "knn = KNeighborsClassifier(n_neighbors = 17)\n",
    "knn.fit(X_train, y_train)\n",
    "prediction = knn.predict(X_test)\n",
    "elapsedTime = timeit.default_timer() - startTime\n",
    "print(\"time taken : \",elapsedTime)\n",
    "error = np.mean(prediction != y_test)\n",
    "print(\"error : \",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, prediction))\n",
    "print ('\\n')\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>'''OUR SCA IS TAKIING VERY REDUCED TIME OF 0.0098 AND PROVIDING ACCURACY OF 94%'''</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
