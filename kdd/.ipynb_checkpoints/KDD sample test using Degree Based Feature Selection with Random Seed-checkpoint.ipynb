{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv(\"kddTrain.csv\")\n",
    "testData = pd.read_csv(\"kddTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdScaler.fit(trainData.drop('41', axis=1))\n",
    "X_train = stdScaler.transform(trainData.drop('41', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdScaler.fit(testData.drop('41', axis=1))\n",
    "X_test = stdScaler.transform(testData.drop('41', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trainData['41']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = testData['41']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time :  1251.4817116496465\n"
     ]
    }
   ],
   "source": [
    "startTime = timeit.default_timer()\n",
    "knn = KNeighborsClassifier(n_neighbors= 1, n_jobs=-1)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "elapsedTime = timeit.default_timer() - startTime\n",
    "print(\"elapsed time : \",elapsedTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 25099    954]\n",
      " [   385 138236]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.96      0.97     26053\n",
      "          1       0.99      1.00      1.00    138621\n",
      "\n",
      "avg / total       0.99      0.99      0.99    164674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print ('\\n')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SCA IMPLEMENTATION\n",
    "#begin\n",
    "errorRate = []\n",
    "totalFeatures = len(X_train[0])\n",
    "a = 1\n",
    "r1 = a\n",
    "t = 0\n",
    "subsets = []    \n",
    "error = 0\n",
    "trainedFeatures = []\n",
    "#SETTING RANDOM SEED FOR REPRODUCABLE RESULTS\n",
    "random.seed(14)\n",
    "#Randomly initialization of each search agents in the population X(t = 1,2,...,m)\n",
    "subsets.append(random.sample(range(1,totalFeatures),int(totalFeatures/3)))#initializing first random subset\n",
    "lowestError = 100 #initializing as highest errorRate for comparison purpose\n",
    "\n",
    "\n",
    "#Function for checking the new generated subset tempSet is already present in the already initialized subsets or not\n",
    "def isRepeat(presentSubsets, newSubset):\n",
    "    #print(subsets)\n",
    "    #print(tempSet)\n",
    "    newSubset.sort()\n",
    "    for subset in presentSubsets:\n",
    "        subset.sort()\n",
    "        if(subset[:] == newSubset[:]):\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "#for generating random search agents in the population   \n",
    "def randomSearchAgents(m, n):\n",
    "    i = 1\n",
    "    while i<m:\n",
    "        X = random.sample(range(1,totalFeatures),n)\n",
    "        if (isRepeat(subsets, X) == False):\n",
    "            subsets.append(X)\n",
    "            i += 1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "#EQUATION 1\n",
    "def updateUsingSineCosine(X):\n",
    "    featureSubset = []\n",
    "    for j in range(len(X)):\n",
    "        #print(X[j])\n",
    "#         if(s%2 == 0):\n",
    "        feature = int(X[j] + r1*math.sin(r2)*abs(r3*P[j]-X[j]))\n",
    "#         else:\n",
    "#             feature = int(X[j] + r1*math.cos(r2)*abs(r3*P[j]-X[j]))\n",
    "        feature %= totalFeatures\n",
    "        featureSubset.append(feature)\n",
    "    return featureSubset\n",
    "\n",
    "\n",
    "#FOR CHECKING THE SCORE FOR EACH SELECTED FEATURE SUBSET\n",
    "def trainTestScore(X_train, y_train, X_test, y_test):\n",
    "    startTime = timeit.default_timer()\n",
    "    knn = KNeighborsClassifier(n_neighbors = 1, n_jobs=-1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    prediction = knn.predict(X_test)\n",
    "    elapsedTime = timeit.default_timer() - startTime\n",
    "    print(\"time taken : \",elapsedTime)\n",
    "    error = np.mean(prediction != y_test)\n",
    "    errorRate.append(error)\n",
    "    return error\n",
    "\n",
    "#here subsets list contains the list of randomly initialized search agent indices\n",
    "\n",
    "#INITIALIZE the max numbers of iteration Tmax, we can take it as the total number of columns present\n",
    "Tmax = totalFeatures\n",
    "P = []\n",
    "\n",
    "'''randomly initialize feature subsets, parameter1 denotes total number of feature subsets, here taken as total no of feature avaiable\n",
    "and parameter 2 denotes number of features in each subsets, here we are considering one third of the total number of features'''\n",
    "\n",
    "randomSearchAgents(totalFeatures, int(totalFeatures/3))\n",
    "\n",
    "print(\"randomly initialized subsets: \",subsets)\n",
    "\n",
    "trainedFeatures = subsets[:]\n",
    "\n",
    "\n",
    "\n",
    "while t<Tmax:\n",
    "    #foreach search agent Xi in the population do\n",
    "    '''NOVEL \n",
    "        here the feature subsets generated by randomSearchAgents method are not repeatative, \n",
    "        if any randomly generated feature subset is already present in the previous generated \n",
    "        ones then it is neglected and a new feature subset is generated randomly and checked again.\n",
    "        This process continues until required number of feature subsets are generated which are all unique\n",
    "    NOVEL'''\n",
    "    for subset in subsets:\n",
    "        #Evaluate Xi via the fitness function. if f(Xi)\n",
    "        if(t > 0):\n",
    "            if(isRepeat(trainedFeatures, subset) == False):\n",
    "                error = trainTestScore(X_train[:,subset], y_train, X_test[:, subset], y_test)\n",
    "                trainedFeatures.append(subset)\n",
    "                #print(trainedFeatures)\n",
    "#                 print('new feature : ',subset, \"t=\",t)\n",
    "            else:\n",
    "                print(\"repeat\")\n",
    "        else:\n",
    "            error = trainTestScore(X_train[:,subset], y_train, X_test[:, subset], y_test)\n",
    "        print(\"subset : \",subset,\" error : \",error, \" lowest error : \", lowestError)\n",
    "        #if f(Xi) better than f(P) then\n",
    "        #Set P = Xi;\n",
    "        if (error < lowestError):\n",
    "            P = subset\n",
    "            lowestError = error\n",
    "\n",
    "    #Update r1 using equation 2\n",
    "\n",
    "    r1 = a - t*(a/Tmax)#equation 2\n",
    "\n",
    "    #Generate randomly new values for r2, r3 and s.\n",
    "\n",
    "    r2 = random.uniform(0.1, 1.0)\n",
    "    r3 = random.uniform(0.1, 1.0)\n",
    "    print('\\n\\n r2:',r2,' r3:',r3,' r1:',r1)\n",
    "    #foreach search agent Xi in the population do\n",
    "    #Update Xi using equation 1.\n",
    "    for i in range(len(subsets)):\n",
    "        subsets[i] = updateUsingSineCosine(subsets[i])\n",
    "#     print(subsets)\n",
    "#     print('\\n\\n\\n\\nIteration number: ',t,'\\n\\n\\n\\n')\n",
    "    t += 1\n",
    "#Return P best solution obtained so far.\n",
    "print(\"best solution: \",P)\n",
    "print(lowestError)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
