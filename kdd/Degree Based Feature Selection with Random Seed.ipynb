{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv('kddTrain.csv')\n",
    "dfTest = pd.read_csv('kddTest.csv')\n",
    "#It can be found here https://mega.nz/#!qpNWUBia!2rAtAmt8F3lcXqSC18yhKhRonlFt0DdnB51c24uAXzk\n",
    "#P.S. open the link in Desktop browser or in desktop mode of your mobile browser for best availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2  3     4  5  6  7  8  9 ...   32   33   34   35   36   37   38  \\\n",
       "0  0  0  14  9  1032  0  0  0  0  0 ...  255  1.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1  0  0  14  9  1032  0  0  0  0  0 ...  255  1.0  0.0  1.0  0.0  0.0  0.0   \n",
       "2  0  0  14  9  1032  0  0  0  0  0 ...  255  1.0  0.0  1.0  0.0  0.0  0.0   \n",
       "3  0  0  14  9  1032  0  0  0  0  0 ...  255  1.0  0.0  1.0  0.0  0.0  0.0   \n",
       "4  0  0  14  9  1032  0  0  0  0  0 ...  255  1.0  0.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "    39   40  41  \n",
       "0  0.0  0.0   1  \n",
       "1  0.0  0.0   1  \n",
       "2  0.0  0.0   1  \n",
       "3  0.0  0.0   1  \n",
       "4  0.0  0.0   1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Scaling the training set</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(dfTrain.drop('41', axis=1))\n",
    "scaledTrainingFeatures = scaler.transform(dfTrain.drop('41', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Scaling the testing set</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(dfTest.drop('41', axis=1))\n",
    "scaledTestingFeatures = scaler.transform(dfTest.drop('41', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03263088, -0.71722614, -0.55780068, ..., -0.38013425,\n",
       "        -0.13611098, -0.13271038],\n",
       "       [-0.03263088, -0.71722614, -0.55780068, ..., -0.38013425,\n",
       "        -0.13611098, -0.13271038],\n",
       "       [-0.03263088, -0.71722614, -0.55780068, ..., -0.38013425,\n",
       "        -0.13611098, -0.13271038],\n",
       "       ...,\n",
       "       [-0.03263088,  1.16473534,  0.14314134, ..., -0.38013425,\n",
       "        -0.13611098, -0.13271038],\n",
       "       [-0.03263088, -0.71722614, -0.55780068, ..., -0.38013425,\n",
       "        -0.13611098, -0.13271038],\n",
       "       [-0.03263088,  1.16473534,  2.15834965, ...,  2.63587189,\n",
       "        -0.13611098, -0.13271038]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledTrainingFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainFeatures = pd.DataFrame(scaledTrainingFeatures, columns=dfTrain.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.032631</td>\n",
       "      <td>-0.717226</td>\n",
       "      <td>-0.557801</td>\n",
       "      <td>0.390241</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.028888</td>\n",
       "      <td>-0.007185</td>\n",
       "      <td>-0.037076</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.051478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388857</td>\n",
       "      <td>0.471474</td>\n",
       "      <td>0.44098</td>\n",
       "      <td>-0.216596</td>\n",
       "      <td>0.724146</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.381528</td>\n",
       "      <td>-0.380134</td>\n",
       "      <td>-0.136111</td>\n",
       "      <td>-0.13271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.032631</td>\n",
       "      <td>-0.717226</td>\n",
       "      <td>-0.557801</td>\n",
       "      <td>0.390241</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.028888</td>\n",
       "      <td>-0.007185</td>\n",
       "      <td>-0.037076</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.051478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388857</td>\n",
       "      <td>0.471474</td>\n",
       "      <td>0.44098</td>\n",
       "      <td>-0.216596</td>\n",
       "      <td>0.724146</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.381528</td>\n",
       "      <td>-0.380134</td>\n",
       "      <td>-0.136111</td>\n",
       "      <td>-0.13271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.032631</td>\n",
       "      <td>-0.717226</td>\n",
       "      <td>-0.557801</td>\n",
       "      <td>0.390241</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.028888</td>\n",
       "      <td>-0.007185</td>\n",
       "      <td>-0.037076</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.051478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388857</td>\n",
       "      <td>0.471474</td>\n",
       "      <td>0.44098</td>\n",
       "      <td>-0.216596</td>\n",
       "      <td>0.724146</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.381528</td>\n",
       "      <td>-0.380134</td>\n",
       "      <td>-0.136111</td>\n",
       "      <td>-0.13271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.032631</td>\n",
       "      <td>-0.717226</td>\n",
       "      <td>-0.557801</td>\n",
       "      <td>0.390241</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.028888</td>\n",
       "      <td>-0.007185</td>\n",
       "      <td>-0.037076</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.051478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388857</td>\n",
       "      <td>0.471474</td>\n",
       "      <td>0.44098</td>\n",
       "      <td>-0.216596</td>\n",
       "      <td>0.724146</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.381528</td>\n",
       "      <td>-0.380134</td>\n",
       "      <td>-0.136111</td>\n",
       "      <td>-0.13271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.032631</td>\n",
       "      <td>-0.717226</td>\n",
       "      <td>-0.557801</td>\n",
       "      <td>0.390241</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.028888</td>\n",
       "      <td>-0.007185</td>\n",
       "      <td>-0.037076</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.051478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388857</td>\n",
       "      <td>0.471474</td>\n",
       "      <td>0.44098</td>\n",
       "      <td>-0.216596</td>\n",
       "      <td>0.724146</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.381528</td>\n",
       "      <td>-0.380134</td>\n",
       "      <td>-0.136111</td>\n",
       "      <td>-0.13271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.032631 -0.717226 -0.557801  0.390241 -0.002681 -0.028888 -0.007185   \n",
       "1 -0.032631 -0.717226 -0.557801  0.390241 -0.002681 -0.028888 -0.007185   \n",
       "2 -0.032631 -0.717226 -0.557801  0.390241 -0.002681 -0.028888 -0.007185   \n",
       "3 -0.032631 -0.717226 -0.557801  0.390241 -0.002681 -0.028888 -0.007185   \n",
       "4 -0.032631 -0.717226 -0.557801  0.390241 -0.002681 -0.028888 -0.007185   \n",
       "\n",
       "          7         8         9   ...           31        32       33  \\\n",
       "0 -0.037076 -0.003149 -0.051478   ...     0.388857  0.471474  0.44098   \n",
       "1 -0.037076 -0.003149 -0.051478   ...     0.388857  0.471474  0.44098   \n",
       "2 -0.037076 -0.003149 -0.051478   ...     0.388857  0.471474  0.44098   \n",
       "3 -0.037076 -0.003149 -0.051478   ...     0.388857  0.471474  0.44098   \n",
       "4 -0.037076 -0.003149 -0.051478   ...     0.388857  0.471474  0.44098   \n",
       "\n",
       "         34        35     36        37        38        39       40  \n",
       "0 -0.216596  0.724146 -0.187 -0.381528 -0.380134 -0.136111 -0.13271  \n",
       "1 -0.216596  0.724146 -0.187 -0.381528 -0.380134 -0.136111 -0.13271  \n",
       "2 -0.216596  0.724146 -0.187 -0.381528 -0.380134 -0.136111 -0.13271  \n",
       "3 -0.216596  0.724146 -0.187 -0.381528 -0.380134 -0.136111 -0.13271  \n",
       "4 -0.216596  0.724146 -0.187 -0.381528 -0.380134 -0.136111 -0.13271  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrainFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dfTrainFeatures\n",
    "y_train = dfTrain['41']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestFeatures = pd.DataFrame(scaledTestingFeatures, columns=dfTest.columns[:-1])\n",
    "X_test = dfTestFeatures\n",
    "y_test = dfTest['41']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 25136    917]\n",
      " [   776 137845]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.97     26053\n",
      "          1       0.99      0.99      0.99    138621\n",
      "\n",
      "avg / total       0.99      0.99      0.99    164674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print ('\\n')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorRate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    predictionSamples = knn.predict(X_test)\n",
    "    errorRate.append(np.mean(predictionSamples != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15dafb7f668>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15dad708a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,40), errorRate, color='blue', linestyle='dashed', marker='o',\n",
    "     markerfacecolor='red', markersize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nparray = scaledTrainingFeatures\n",
    "X_test_nparray = scaledTestingFeatures\n",
    "y_train_nparray = dfTrain['41']\n",
    "y_test_nparray = dfTest['41']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1237c2d15613>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstartTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_nparray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_nparray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_nparray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0melapsedTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "startTime = timeit.default_timer()\n",
    "knn = KNeighborsClassifier(n_neighbors= 1)\n",
    "knn.fit(X_train_nparray, y_train_nparray)\n",
    "predictions = knn.predict(X_test_nparray)\n",
    "elapsedTime = timeit.default_timer() - startTime\n",
    "print(\"elapsed time : \",elapsedTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 24747   1306]\n",
      " [   828 137793]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96     26053\n",
      "          1       0.99      0.99      0.99    138621\n",
      "\n",
      "avg / total       0.99      0.99      0.99    164674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_nparray, predictions))\n",
    "print ('\\n')\n",
    "print(classification_report(y_test_nparray, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TILL THIS ONLY KNN IS USED WHICH IS PROVIDING 96% ACCURACY WITH COMPUTATION TIME OF 0.0124'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''TILL THIS ONLY KNN IS USED WHICH IS PROVIDING 96% ACCURACY WITH COMPUTATION TIME OF 0.0124'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOW FROM HERE WE HAVE PASSED THE WHOLE DATA TO OUR SCA ALGORITHM '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''NOW FROM HERE WE HAVE PASSED THE WHOLE DATA TO OUR SCA ALGORITHM '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfTrainedFeatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-0fd29aa06afd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfTrainedFeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dfTrainedFeatures' is not defined"
     ]
    }
   ],
   "source": [
    "data = dfTrainedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "#SCA IMPLEMENTATION\n",
    "#begin\n",
    "totalFeatures = len(data.columns[:-1])\n",
    "a = 1\n",
    "r1 = a\n",
    "t = 0\n",
    "subsets = []    \n",
    "trainedFeatures = []\n",
    "#SETTING RANDOM SEED FOR REPRODUCABLE RESULTS\n",
    "random.seed(14)\n",
    "#Randomly initialization of each search agents in the population X(t = 1,2,...,m)\n",
    "subsets.append(random.sample(range(1,totalFeatures),int(totalFeatures/3)))#initializing first random subset\n",
    "lowestError = 100 #initializing as highest errorRate for comparison purpose\n",
    "\n",
    "\n",
    "#Function for checking the new generated subset tempSet is already present in the already initialized subsets or not\n",
    "def isRepeat(presentSubsets, newSubset):\n",
    "    #print(subsets)\n",
    "    #print(tempSet)\n",
    "    newSubset.sort()\n",
    "    for subset in presentSubsets:\n",
    "        subset.sort()\n",
    "        if(subset[:] == newSubset[:]):\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "#for generating random search agents in the population   \n",
    "def randomSearchAgents(m, n):\n",
    "    i = 1\n",
    "    while i<m:\n",
    "        X = random.sample(range(1,totalFeatures),n)\n",
    "        if (isRepeat(subsets, X) == False):\n",
    "            subsets.append(X)\n",
    "            i += 1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "#EQUATION 1\n",
    "def updateUsingSineCosine(X):\n",
    "    featureSubset = []\n",
    "    for j in range(len(X)):\n",
    "        #print(X[j])\n",
    "#         if(s%2 == 0):\n",
    "        feature = int(X[j] + r1*math.sin(r2)*abs(r3*P[j]-X[j]))\n",
    "#         else:\n",
    "#             feature = int(X[j] + r1*math.cos(r2)*abs(r3*P[j]-X[j]))\n",
    "        feature %= totalFeatures\n",
    "        featureSubset.append(feature)\n",
    "    return featureSubset\n",
    "\n",
    "\n",
    "#FOR CHECKING THE SCORE FOR EACH SELECTED FEATURE SUBSET\n",
    "def trainTestScore(X, y):\n",
    "    X.head()\n",
    "    startTime = timeit.default_timer()\n",
    "    knn = KNeighborsClassifier(n_neighbors = 17)\n",
    "    knn.fit(X_train, y_train)\n",
    "    prediction = knn.predict(X_test)\n",
    "    elapsedTime = timeit.default_timer() - startTime\n",
    "#     print(\"time taken : \",elapsedTime)\n",
    "    error = np.mean(prediction != y_test)\n",
    "    errorRate.append(error)\n",
    "    return error\n",
    "\n",
    "#here subsets list contains the list of randomly initialized search agent indices\n",
    "\n",
    "#INITIALIZE the max numbers of iteration Tmax, we can take it as the total number of columns present\n",
    "Tmax = totalFeatures\n",
    "P = []\n",
    "\n",
    "'''randomly initialize feature subsets, parameter1 denotes total number of feature subsets, here taken as total no of feature avaiable\n",
    "and parameter 2 denotes number of features in each subsets, here we are considering one third of the total number of features'''\n",
    "\n",
    "randomSearchAgents(totalFeatures, int(totalFeatures/3))\n",
    "\n",
    "print(\"randomly initialized subsets: \",subsets)\n",
    "\n",
    "trainedFeatures = subsets[:]\n",
    "\n",
    "\n",
    "\n",
    "while t<Tmax:\n",
    "    #foreach search agent Xi in the population do\n",
    "    '''NOVEL \n",
    "        here the feature subsets generated by randomSearchAgents method are not repeatative, \n",
    "        if any randomly generated feature subset is already present in the previous generated \n",
    "        ones then it is neglected and a new feature subset is generated randomly and checked again.\n",
    "        This process continues until required number of feature subsets are generated which are all unique\n",
    "    NOVEL'''\n",
    "    for subset in subsets:\n",
    "        #Evaluate Xi via the fitness function. if f(Xi)\n",
    "        if(t > 0):\n",
    "            if(isRepeat(trainedFeatures, subset) == False):\n",
    "                trainedFeatures.append(subset)\n",
    "                #print(trainedFeatures)\n",
    "#                 print('new feature : ',subset, \"t=\",t)\n",
    "#             else:\n",
    "#                 print(\"repeat\")\n",
    "        error = trainTestScore(data.iloc[:,subset], df['TARGET CLASS'])\n",
    "#       print(\"subset : \",subset,\" error : \",error, \" lowest error : \", lowestError)\n",
    "        #if f(Xi) better than f(P) then\n",
    "        #Set P = Xi;\n",
    "        if (error < lowestError):\n",
    "            P = subset\n",
    "            lowestError = error\n",
    "\n",
    "    #Update r1 using equation 2\n",
    "\n",
    "    r1 = a - t*(a/Tmax)#equation 2\n",
    "\n",
    "    #Generate randomly new values for r2, r3 and s.\n",
    "\n",
    "    r2 = random.uniform(0.1, 1.0)\n",
    "    r3 = random.uniform(0.1, 1.0)\n",
    "#   print('\\n\\n r2:',r2,' r3:',r3,' r1:',r1)\n",
    "    #foreach search agent Xi in the population do\n",
    "    #Update Xi using equation 1.\n",
    "    for i in range(len(subsets)):\n",
    "        subsets[i] = updateUsingSineCosine(subsets[i])\n",
    "#     print(subsets)\n",
    "#     print(P)\n",
    "    t += 1\n",
    "#Return P best solution obtained so far.\n",
    "print(\"best solution: \",P)\n",
    "print(lowestError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = timeit.default_timer()\n",
    "knn = KNeighborsClassifier(n_neighbors = 17)\n",
    "knn.fit(X_train, y_train)\n",
    "prediction = knn.predict(X_test)\n",
    "elapsedTime = timeit.default_timer() - startTime\n",
    "print(\"time taken : \",elapsedTime)\n",
    "error = np.mean(prediction != y_test)\n",
    "print(\"error : \",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, prediction))\n",
    "print ('\\n')\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>'''OUR SCA IS TAKIING VERY REDUCED TIME OF 0.0098 AND PROVIDING ACCURACY OF 94%'''</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
