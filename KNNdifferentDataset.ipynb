{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Classified Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       WTT       PTI       EQW       SBI       LQE       QWG  \\\n",
       "0           0  0.913917  1.162073  0.567946  0.755464  0.780862  0.352608   \n",
       "1           1  0.635632  1.003722  0.535342  0.825645  0.924109  0.648450   \n",
       "2           2  0.721360  1.201493  0.921990  0.855595  1.526629  0.720781   \n",
       "3           3  1.234204  1.386726  0.653046  0.825624  1.142504  0.875128   \n",
       "4           4  1.279491  0.949750  0.627280  0.668976  1.232537  0.703727   \n",
       "\n",
       "        FDJ       PJF       HQE       NXJ  TARGET CLASS  \n",
       "0  0.759697  0.643798  0.879422  1.231409             1  \n",
       "1  0.675334  1.013546  0.621552  1.492702             0  \n",
       "2  1.626351  1.154483  0.957877  1.285597             0  \n",
       "3  1.409708  1.380003  1.522692  1.153093             1  \n",
       "4  1.115596  0.646691  1.463812  1.419167             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(df.drop('TARGET CLASS', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaledFeatures = scaler.transform(df.drop('TARGET CLASS', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73031962, -0.12354188,  0.18590747, ..., -1.48236813,\n",
       "        -0.9497194 , -0.64331425],\n",
       "       [-1.72685552, -1.08483602, -0.43034845, ..., -0.20224031,\n",
       "        -1.82805088,  0.63675862],\n",
       "       [-1.72339142, -0.78870217,  0.33931821, ...,  0.28570652,\n",
       "        -0.68249379, -0.37784986],\n",
       "       ...,\n",
       "       [ 1.72339142,  0.64177714, -0.51308341, ..., -2.36249443,\n",
       "        -0.81426092,  0.11159651],\n",
       "       [ 1.72685552,  0.46707241, -0.98278576, ..., -0.03677699,\n",
       "         0.40602453, -0.85567   ],\n",
       "       [ 1.73031962, -0.38765353, -0.59589427, ..., -0.56778932,\n",
       "         0.3369971 ,  0.01034996]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfFeatures = pd.DataFrame(scaledFeatures, columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.730320</td>\n",
       "      <td>-0.123542</td>\n",
       "      <td>0.185907</td>\n",
       "      <td>-0.913431</td>\n",
       "      <td>0.319629</td>\n",
       "      <td>-1.033637</td>\n",
       "      <td>-2.308375</td>\n",
       "      <td>-0.798951</td>\n",
       "      <td>-1.482368</td>\n",
       "      <td>-0.949719</td>\n",
       "      <td>-0.643314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.726856</td>\n",
       "      <td>-1.084836</td>\n",
       "      <td>-0.430348</td>\n",
       "      <td>-1.025313</td>\n",
       "      <td>0.625388</td>\n",
       "      <td>-0.444847</td>\n",
       "      <td>-1.152706</td>\n",
       "      <td>-1.129797</td>\n",
       "      <td>-0.202240</td>\n",
       "      <td>-1.828051</td>\n",
       "      <td>0.636759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.723391</td>\n",
       "      <td>-0.788702</td>\n",
       "      <td>0.339318</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.755873</td>\n",
       "      <td>2.031693</td>\n",
       "      <td>-0.870156</td>\n",
       "      <td>2.599818</td>\n",
       "      <td>0.285707</td>\n",
       "      <td>-0.682494</td>\n",
       "      <td>-0.377850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.719927</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>1.060193</td>\n",
       "      <td>-0.621399</td>\n",
       "      <td>0.625299</td>\n",
       "      <td>0.452820</td>\n",
       "      <td>-0.267220</td>\n",
       "      <td>1.750208</td>\n",
       "      <td>1.066491</td>\n",
       "      <td>1.241325</td>\n",
       "      <td>-1.026987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.716463</td>\n",
       "      <td>1.139275</td>\n",
       "      <td>-0.640392</td>\n",
       "      <td>-0.709819</td>\n",
       "      <td>-0.057175</td>\n",
       "      <td>0.822886</td>\n",
       "      <td>-0.936773</td>\n",
       "      <td>0.596782</td>\n",
       "      <td>-1.472352</td>\n",
       "      <td>1.040772</td>\n",
       "      <td>0.276510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       WTT       PTI       EQW       SBI       LQE       QWG  \\\n",
       "0   -1.730320 -0.123542  0.185907 -0.913431  0.319629 -1.033637 -2.308375   \n",
       "1   -1.726856 -1.084836 -0.430348 -1.025313  0.625388 -0.444847 -1.152706   \n",
       "2   -1.723391 -0.788702  0.339318  0.301511  0.755873  2.031693 -0.870156   \n",
       "3   -1.719927  0.982841  1.060193 -0.621399  0.625299  0.452820 -0.267220   \n",
       "4   -1.716463  1.139275 -0.640392 -0.709819 -0.057175  0.822886 -0.936773   \n",
       "\n",
       "        FDJ       PJF       HQE       NXJ  \n",
       "0 -0.798951 -1.482368 -0.949719 -0.643314  \n",
       "1 -1.129797 -0.202240 -1.828051  0.636759  \n",
       "2  2.599818  0.285707 -0.682494 -0.377850  \n",
       "3  1.750208  1.066491  1.241325 -1.026987  \n",
       "4  0.596782 -1.472352  1.040772  0.276510  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dfFeatures\n",
    "y = df['TARGET CLASS']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147  12]\n",
      " [ 12 129]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92       159\n",
      "          1       0.91      0.91      0.91       141\n",
      "\n",
      "avg / total       0.92      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print ('\\n')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errorRate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    predictionSamples = knn.predict(X_test)\n",
    "    errorRate.append(np.mean(predictionSamples != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ec06b16908>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ec06a87a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,40), errorRate, color='blue', linestyle='dashed', marker='o',\n",
    "     markerfacecolor='red', markersize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time :  0.012429314447615525\n"
     ]
    }
   ],
   "source": [
    "startTime = timeit.default_timer()\n",
    "knn = KNeighborsClassifier(n_neighbors= 30)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "elapsedTime = timeit.default_timer() - startTime\n",
    "print(\"elapsed time : \",elapsedTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[153   6]\n",
      " [  7 134]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96       159\n",
      "          1       0.96      0.95      0.95       141\n",
      "\n",
      "avg / total       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print ('\\n')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>TILL THIS ONLY KNN IS USED WHICH IS PROVIDING 96% ACCURACY WITH COMPUTATION TIME OF 0.0124</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>NOW FROM DOWNWARDS HERE WE HAVE PASSED THE WHOLE DATA TO OUR SCA ALGORITHM</h6> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = dfFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken :  0.014380271139499547\n",
      "subset :  [5, 2, 6]  error :  0.296969696969697  lowest error :  100\n",
      "time taken :  0.009487755714511895\n",
      "subset :  [4, 8, 7]  error :  0.23939393939393938  lowest error :  0.296969696969697\n",
      "time taken :  0.009525092337248957\n",
      "subset :  [1, 5, 7]  error :  0.2606060606060606  lowest error :  0.23939393939393938\n",
      "time taken :  0.009463179709672316\n",
      "subset :  [3, 1, 6]  error :  0.1606060606060606  lowest error :  0.23939393939393938\n",
      "time taken :  0.009502879409797785\n",
      "subset :  [9, 4, 7]  error :  0.21515151515151515  lowest error :  0.1606060606060606\n",
      "time taken :  0.010982165854949572\n",
      "subset :  [9, 5, 6]  error :  0.19393939393939394  lowest error :  0.1606060606060606\n",
      "[3, 1, 6]\n",
      "time taken :  0.009644664053103075\n",
      "subset :  [7, 2, 8]  error :  0.18181818181818182  lowest error :  0.1606060606060606\n",
      "time taken :  0.00944238462865421\n",
      "subset :  [5, 1, 9]  error :  0.14545454545454545  lowest error :  0.1606060606060606\n",
      "time taken :  0.009255701514968906\n",
      "subset :  [1, 7, 9]  error :  0.18181818181818182  lowest error :  0.14545454545454545\n",
      "time taken :  0.009529345876548106\n",
      "subset :  [4, 1, 8]  error :  0.15757575757575756  lowest error :  0.14545454545454545\n",
      "time taken :  0.00948255694425737\n",
      "subset :  [2, 5, 9]  error :  0.15454545454545454  lowest error :  0.14545454545454545\n",
      "time taken :  0.009362512612925561\n",
      "subset :  [2, 7, 8]  error :  0.18181818181818182  lowest error :  0.14545454545454545\n",
      "time taken :  0.00947215940374832\n",
      "subset :  [7, 2, 1]  error :  0.17575757575757575  lowest error :  0.14545454545454545\n",
      "time taken :  0.01055917500242215\n",
      "subset :  [9, 4, 2]  error :  0.1696969696969697  lowest error :  0.14545454545454545\n",
      "time taken :  0.010003379200665408\n",
      "subset :  [1, 2, 5]  error :  0.18484848484848485  lowest error :  0.14545454545454545\n",
      "time taken :  0.011066764025455034\n",
      "subset :  [4, 1, 9]  error :  0.16666666666666666  lowest error :  0.14545454545454545\n",
      "time taken :  0.01337360017203204\n",
      "subset :  [3, 2, 9]  error :  0.09090909090909091  lowest error :  0.14545454545454545\n",
      "[3, 2, 9]\n",
      "time taken :  0.014117969549384768\n",
      "subset :  [7, 3, 3]  error :  0.19696969696969696  lowest error :  0.09090909090909091\n",
      "time taken :  0.009727844377175554\n",
      "subset :  [5, 2, 3]  error :  0.17272727272727273  lowest error :  0.09090909090909091\n",
      "time taken :  0.009621505894696514\n",
      "subset :  [3, 8, 3]  error :  0.1303030303030303  lowest error :  0.09090909090909091\n",
      "time taken :  0.010426370053192857\n",
      "subset :  [5, 2, 3]  error :  0.17272727272727273  lowest error :  0.09090909090909091\n",
      "time taken :  0.011155615735259694\n",
      "subset :  [4, 5, 3]  error :  0.20909090909090908  lowest error :  0.09090909090909091\n",
      "time taken :  0.009353060303371907\n",
      "subset :  [4, 8, 3]  error :  0.12424242424242424  lowest error :  0.09090909090909091\n",
      "time taken :  0.010463706675929885\n",
      "subset :  [7, 3, 0]  error :  0.19393939393939394  lowest error :  0.09090909090909091\n",
      "time taken :  0.00965695205552286\n",
      "subset :  [0, 4, 0]  error :  0.48484848484848486  lowest error :  0.09090909090909091\n",
      "time taken :  0.010857867984318648\n",
      "subset :  [3, 3, 2]  error :  0.15757575757575756  lowest error :  0.09090909090909091\n",
      "time taken :  0.021094719230960124\n",
      "subset :  [5, 2, 3]  error :  0.17272727272727273  lowest error :  0.09090909090909091\n",
      "time taken :  0.009614889278008909\n",
      "subset :  [4, 3, 3]  error :  0.21515151515151515  lowest error :  0.09090909090909091\n",
      "time taken :  0.00950618771814149\n",
      "subset :  [6, 1, 5]  error :  0.25757575757575757  lowest error :  0.09090909090909091\n",
      "time taken :  0.01053837992140405\n",
      "subset :  [9, 4, 3]  error :  0.11212121212121212  lowest error :  0.09090909090909091\n",
      "time taken :  0.009939103495700374\n",
      "subset :  [7, 9, 4]  error :  0.21515151515151515  lowest error :  0.09090909090909091\n",
      "time taken :  0.009771797616600186\n",
      "subset :  [2, 7, 9]  error :  0.16363636363636364  lowest error :  0.09090909090909091\n",
      "time taken :  0.011519529653076677\n",
      "subset :  [6, 1, 5]  error :  0.25757575757575757  lowest error :  0.09090909090909091\n",
      "[3, 2, 9]\n",
      "time taken :  0.013220000141784594\n",
      "subset :  [9, 3, 7]  error :  0.10909090909090909  lowest error :  0.09090909090909091\n",
      "time taken :  0.009679637598451696\n",
      "subset :  [5, 2, 7]  error :  0.32727272727272727  lowest error :  0.09090909090909091\n",
      "time taken :  0.01323276075968205\n",
      "subset :  [3, 1, 7]  error :  0.1484848484848485  lowest error :  0.09090909090909091\n",
      "time taken :  0.013706321468321736\n",
      "subset :  [5, 2, 7]  error :  0.32727272727272727  lowest error :  0.09090909090909091\n",
      "time taken :  0.0114113007086869\n",
      "subset :  [4, 6, 7]  error :  0.37575757575757573  lowest error :  0.09090909090909091\n",
      "time taken :  0.010246303556195158\n",
      "subset :  [4, 1, 7]  error :  0.2696969696969697  lowest error :  0.09090909090909091\n",
      "time taken :  0.011742604158543557\n",
      "subset :  [9, 3, 5]  error :  0.10909090909090909  lowest error :  0.09090909090909091\n",
      "time taken :  0.008882335287598297\n",
      "subset :  [1, 5, 5]  error :  0.2545454545454545  lowest error :  0.09090909090909091\n",
      "time taken :  0.009292565522228236\n",
      "subset :  [3, 3, 6]  error :  0.21818181818181817  lowest error :  0.09090909090909091\n",
      "time taken :  0.010101683220023805\n",
      "subset :  [5, 2, 7]  error :  0.32727272727272727  lowest error :  0.09090909090909091\n",
      "time taken :  0.01002890043646043\n",
      "subset :  [4, 3, 7]  error :  0.21212121212121213  lowest error :  0.09090909090909091\n",
      "time taken :  0.011581914896130918\n",
      "subset :  [7, 1, 8]  error :  0.15151515151515152  lowest error :  0.09090909090909091\n",
      "time taken :  0.011638156137975364\n",
      "subset :  [2, 5, 7]  error :  0.32727272727272727  lowest error :  0.09090909090909091\n",
      "time taken :  0.01075767350304957\n",
      "subset :  [9, 2, 7]  error :  0.16363636363636364  lowest error :  0.09090909090909091\n",
      "time taken :  0.011244467445064354\n",
      "subset :  [2, 9, 9]  error :  0.15151515151515152  lowest error :  0.09090909090909091\n",
      "time taken :  0.009634266512594025\n",
      "subset :  [7, 1, 8]  error :  0.15151515151515152  lowest error :  0.09090909090909091\n",
      "time taken :  0.009243413512549092\n",
      "subset :  [4, 7, 2]  error :  0.2878787878787879  lowest error :  0.09090909090909091\n",
      "time taken :  0.01244349291194935\n",
      "subset :  [8, 6, 4]  error :  0.23636363636363636  lowest error :  0.09090909090909091\n",
      "time taken :  0.010590840239427024\n",
      "subset :  [7, 9, 6]  error :  0.18787878787878787  lowest error :  0.09090909090909091\n",
      "time taken :  0.009813860394114027\n",
      "subset :  [6, 4, 1]  error :  0.24545454545454545  lowest error :  0.09090909090909091\n",
      "time taken :  0.009574244346928218\n",
      "subset :  [8, 6, 5]  error :  0.20909090909090908  lowest error :  0.09090909090909091\n",
      "[3, 2, 9]\n",
      "time taken :  0.010280331870588633\n",
      "subset :  [9, 3, 8]  error :  0.06060606060606061  lowest error :  0.09090909090909091\n",
      "time taken :  0.009156452264655224\n",
      "subset :  [5, 2, 8]  error :  0.17575757575757575  lowest error :  0.06060606060606061\n",
      "time taken :  0.011566791200845028\n",
      "subset :  [3, 1, 8]  error :  0.09696969696969697  lowest error :  0.06060606060606061\n",
      "time taken :  0.012963369937402103\n",
      "subset :  [5, 2, 8]  error :  0.17575757575757575  lowest error :  0.06060606060606061\n",
      "time taken :  0.012702013578242521\n",
      "subset :  [4, 6, 8]  error :  0.23636363636363636  lowest error :  0.06060606060606061\n",
      "time taken :  0.011172157276978734\n",
      "subset :  [4, 1, 8]  error :  0.15757575757575756  lowest error :  0.06060606060606061\n",
      "time taken :  0.012057838682159039\n",
      "subset :  [9, 3, 6]  error :  0.10303030303030303  lowest error :  0.06060606060606061\n",
      "time taken :  0.009742022841505937\n",
      "subset :  [1, 5, 6]  error :  0.25757575757575757  lowest error :  0.06060606060606061\n",
      "time taken :  0.009819059164368538\n",
      "subset :  [3, 3, 7]  error :  0.19696969696969696  lowest error :  0.06060606060606061\n",
      "time taken :  0.010127204455818717\n",
      "subset :  [5, 2, 8]  error :  0.17575757575757575  lowest error :  0.06060606060606061\n",
      "time taken :  0.009849779170418183\n",
      "subset :  [4, 3, 8]  error :  0.12424242424242424  lowest error :  0.06060606060606061\n",
      "time taken :  0.011179719124621679\n",
      "subset :  [7, 1, 8]  error :  0.15151515151515152  lowest error :  0.06060606060606061\n",
      "time taken :  0.0104088832805187\n",
      "subset :  [2, 5, 8]  error :  0.17575757575757575  lowest error :  0.06060606060606061\n",
      "time taken :  0.012611744022005045\n",
      "subset :  [9, 2, 8]  error :  0.11212121212121212  lowest error :  0.06060606060606061\n",
      "time taken :  0.010018030280473544\n",
      "subset :  [2, 9, 9]  error :  0.15151515151515152  lowest error :  0.06060606060606061\n",
      "time taken :  0.010391869123321795\n",
      "subset :  [7, 1, 8]  error :  0.15151515151515152  lowest error :  0.06060606060606061\n",
      "time taken :  0.009920671492070543\n",
      "subset :  [4, 7, 3]  error :  0.21212121212121213  lowest error :  0.06060606060606061\n",
      "time taken :  0.009317141527067863\n",
      "subset :  [8, 6, 5]  error :  0.20909090909090908  lowest error :  0.06060606060606061\n",
      "time taken :  0.008591676768822554\n",
      "subset :  [7, 9, 7]  error :  0.21212121212121213  lowest error :  0.06060606060606061\n",
      "time taken :  0.010081360754483182\n",
      "subset :  [6, 4, 3]  error :  0.20303030303030303  lowest error :  0.06060606060606061\n",
      "time taken :  0.008295346864314546\n",
      "subset :  [8, 6, 6]  error :  0.23333333333333334  lowest error :  0.06060606060606061\n",
      "time taken :  0.009785503465453038\n",
      "subset :  [6, 2, 5]  error :  0.296969696969697  lowest error :  0.06060606060606061\n",
      "time taken :  0.013767288864943161\n",
      "subset :  [8, 7, 2]  error :  0.18181818181818182  lowest error :  0.06060606060606061\n",
      "time taken :  0.010507659915354406\n",
      "subset :  [2, 5, 8]  error :  0.17575757575757575  lowest error :  0.06060606060606061\n",
      "time taken :  0.010896149838010905\n",
      "subset :  [9, 8, 3]  error :  0.06060606060606061  lowest error :  0.06060606060606061\n",
      "time taken :  0.012290365497179767\n",
      "subset :  [1, 7, 4]  error :  0.2696969696969697  lowest error :  0.06060606060606061\n",
      "[9, 3, 8]\n",
      "time taken :  0.010265680790780163\n",
      "subset :  [9, 3, 8]  error :  0.06060606060606061  lowest error :  0.06060606060606061\n",
      "time taken :  0.010889533221323466\n",
      "subset :  [6, 2, 8]  error :  0.17272727272727273  lowest error :  0.06060606060606061\n",
      "time taken :  0.009213166121977423\n",
      "subset :  [5, 1, 8]  error :  0.15757575757575756  lowest error :  0.06060606060606061\n",
      "time taken :  0.009613944047053513\n",
      "subset :  [6, 2, 8]  error :  0.17272727272727273  lowest error :  0.06060606060606061\n",
      "time taken :  0.008663514321430421\n",
      "subset :  [6, 6, 8]  error :  0.23333333333333334  lowest error :  0.06060606060606061\n",
      "time taken :  0.00952603756820447\n",
      "subset :  [6, 1, 8]  error :  0.14545454545454545  lowest error :  0.06060606060606061\n",
      "time taken :  0.009876718252646244\n",
      "subset :  [9, 3, 7]  error :  0.10909090909090909  lowest error :  0.06060606060606061\n",
      "time taken :  0.010894259376100335\n",
      "subset :  [4, 5, 7]  error :  0.4  lowest error :  0.06060606060606061\n",
      "time taken :  0.009401739697573408\n",
      "subset :  [5, 3, 7]  error :  0.22424242424242424  lowest error :  0.06060606060606061\n",
      "time taken :  0.010128622302251866\n",
      "subset :  [6, 2, 8]  error :  0.17272727272727273  lowest error :  0.06060606060606061\n",
      "time taken :  0.01067260271706627\n",
      "subset :  [6, 3, 8]  error :  0.10909090909090909  lowest error :  0.06060606060606061\n",
      "time taken :  0.01259094894098678\n",
      "subset :  [8, 1, 8]  error :  0.1606060606060606  lowest error :  0.06060606060606061\n",
      "time taken :  0.01290760131103541\n",
      "subset :  [4, 5, 8]  error :  0.22727272727272727  lowest error :  0.06060606060606061\n",
      "time taken :  0.009910746567039386\n",
      "subset :  [9, 2, 8]  error :  0.11212121212121212  lowest error :  0.06060606060606061\n",
      "time taken :  0.010293092488485867\n",
      "subset :  [4, 0, 9]  error :  0.22727272727272727  lowest error :  0.06060606060606061\n",
      "time taken :  0.009095957483511663\n",
      "subset :  [8, 1, 8]  error :  0.1606060606060606  lowest error :  0.06060606060606061\n",
      "time taken :  0.009285476290062933\n",
      "subset :  [6, 8, 5]  error :  0.20909090909090908  lowest error :  0.06060606060606061\n",
      "time taken :  0.009013722390394552\n",
      "subset :  [8, 6, 6]  error :  0.23333333333333334  lowest error :  0.06060606060606061\n",
      "time taken :  0.009810079470292443\n",
      "subset :  [8, 0, 7]  error :  0.23333333333333334  lowest error :  0.06060606060606061\n",
      "time taken :  0.011190116665130478\n",
      "subset :  [7, 4, 5]  error :  0.4  lowest error :  0.06060606060606061\n",
      "time taken :  0.01040746543408555\n",
      "subset :  [8, 6, 7]  error :  0.20606060606060606  lowest error :  0.06060606060606061\n",
      "time taken :  0.010271352176512316\n",
      "subset :  [7, 2, 6]  error :  0.25757575757575757  lowest error :  0.06060606060606061\n",
      "time taken :  0.009151253494400713\n",
      "subset :  [8, 8, 4]  error :  0.2515151515151515  lowest error :  0.06060606060606061\n",
      "time taken :  0.013392504791139404\n",
      "subset :  [4, 5, 8]  error :  0.22727272727272727  lowest error :  0.06060606060606061\n",
      "time taken :  0.00871172110015439\n",
      "subset :  [9, 9, 5]  error :  0.20909090909090908  lowest error :  0.06060606060606061\n",
      "time taken :  0.009949973651687039\n",
      "subset :  [4, 8, 5]  error :  0.22727272727272727  lowest error :  0.06060606060606061\n",
      "time taken :  0.00980440808456029\n",
      "subset :  [8, 5, 6]  error :  0.20909090909090908  lowest error :  0.06060606060606061\n",
      "time taken :  0.009665931749599288\n",
      "subset :  [7, 3, 4]  error :  0.21212121212121213  lowest error :  0.06060606060606061\n",
      "time taken :  0.00939370523445282\n",
      "subset :  [7, 3, 6]  error :  0.20606060606060606  lowest error :  0.06060606060606061\n",
      "time taken :  0.009682945906795748\n",
      "subset :  [1, 2, 3]  error :  0.10606060606060606  lowest error :  0.06060606060606061\n",
      "time taken :  0.009368183998657909\n",
      "subset :  [1, 5, 7]  error :  0.2606060606060606  lowest error :  0.06060606060606061\n",
      "[9, 3, 8]\n",
      "best solution:  [9, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "#SCA IMPLEMENTATION\n",
    "#begin\n",
    "#Randomly initialization of each search agents in the population X(t = 1,2,...,m)\n",
    "a = 1\n",
    "totalFeatures = len(data.columns[:-1])\n",
    "r1 = a\n",
    "t = 0\n",
    "subsets = []\n",
    "subsets.append(random.sample(range(1,totalFeatures),3))#initializing first random subset\n",
    "lowestError = 100 #initializing as highest errorRate for comparison purpose\n",
    "\n",
    "#Function for checking the new generated subset tempSet is already present in the already initialized subsets or not\n",
    "def isRepeat(subsets, tempSet):\n",
    "    #print(subsets)\n",
    "    #print(tempSet)\n",
    "    for subset in subsets:\n",
    "        valueSet = set()\n",
    "        for feature in subset:\n",
    "            valueSet.add(feature)\n",
    "    for feature in tempSet:\n",
    "        if((feature in valueSet) == False):\n",
    "            return False\n",
    "        \n",
    "#for generating random search agents in the population   \n",
    "def randomSearchAgents(m, n):\n",
    "    i = 1\n",
    "    while i<m:\n",
    "        X = random.sample(range(1,totalFeatures),n)\n",
    "        if (isRepeat(subsets, X) == False):\n",
    "            subsets.append(X)\n",
    "            i += 1\n",
    "            \n",
    "#EQUATION 1\n",
    "def updateUsingSineCosine(X):\n",
    "    featureSubset = []\n",
    "    for j in range(len(X)):\n",
    "        #print(X[j])\n",
    "        if(s%2 == 0):\n",
    "            feature = int(X[j] + r1*r2*abs(r3*P[j]-X[j]))\n",
    "        else:\n",
    "            feature = int(X[j] + r1*r2*abs(r3*P[j]-X[j]))\n",
    "        feature %= totalFeatures\n",
    "        featureSubset.append(feature)\n",
    "    return featureSubset\n",
    "\n",
    "\n",
    "#FOR CHECKING THE SCORE FOR EACH SELECTED FEATURE SUBSET\n",
    "def trainTestScore(X, y):\n",
    "    X.head()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "    startTime = timeit.default_timer()\n",
    "    knn = KNeighborsClassifier(n_neighbors = 17)\n",
    "    knn.fit(X_train, y_train)\n",
    "    prediction = knn.predict(X_test)\n",
    "    elapsedTime = timeit.default_timer() - startTime\n",
    "    print(\"time taken : \",elapsedTime)\n",
    "    error = np.mean(prediction != y_test)\n",
    "    errorRate.append(error)\n",
    "    return error\n",
    "\n",
    "#here subsets list contains the list of randomly initialized search agent indices\n",
    "\n",
    "#INITIALIZE the max numbers of iteration Tmax\n",
    "Tmax = 6\n",
    "P = []\n",
    "\n",
    "while t<Tmax:\n",
    "    #foreach search agent Xi in the population do\n",
    "    randomSearchAgents(6, 3)\n",
    "    '''NOVELTY\n",
    "        here the feature subsets generated by randomSearchAgents method are not repeatative, \n",
    "        if any randomly generated feature subset is already present in the previous generated \n",
    "        ones then it is neglected and a new feature subset is generated randomly and checked again.\n",
    "        This process continues until required number of feature subsets are generated which are all unique\n",
    "    NOVEL'''\n",
    "    for subset in subsets:\n",
    "        #Evaluate Xi via the fitness function. if f(Xi)\n",
    "        error = trainTestScore(data.iloc[:,subset], df['TARGET CLASS'])\n",
    "        print(\"subset : \",subset,\" error : \",error, \" lowest error : \", lowestError)\n",
    "        #if f(Xi) better than f(P) then\n",
    "        #Set P = Xi;\n",
    "        if (error < lowestError):\n",
    "            P = subset\n",
    "            lowestError = error\n",
    "    \n",
    "    #Update r1 using equation 2\n",
    "    \n",
    "    r1 = a - t*(a/Tmax)#equation 2\n",
    "    \n",
    "    #Generate randomly new values for r2, r3 and s.\n",
    "    \n",
    "    s = int(round(random.random(),1)*10)\n",
    "    r2 = random.uniform(0.1, 1.0)\n",
    "    r3 = random.uniform(0.1,2.0)\n",
    "    #foreach search agent Xi in the population do\n",
    "    #Update Xi using equation 1.\n",
    "    for i in range(len(subsets)):\n",
    "        subsets[i] = updateUsingSineCosine(subsets[i])\n",
    "    print(P)\n",
    "    t += 1\n",
    "#Return P best solution obtained so far.\n",
    "print(\"best solution: \",P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken :  0.009830401935829514\n",
      "error :  0.06060606060606061\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,P], df['TARGET CLASS'], test_size = 0.33, random_state = 42)\n",
    "startTime = timeit.default_timer()\n",
    "knn = KNeighborsClassifier(n_neighbors = 17)\n",
    "knn.fit(X_train, y_train)\n",
    "prediction = knn.predict(X_test)\n",
    "elapsedTime = timeit.default_timer() - startTime\n",
    "print(\"time taken : \",elapsedTime)\n",
    "error = np.mean(prediction != y_test)\n",
    "print(\"error : \",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[145  10]\n",
      " [ 10 165]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94       155\n",
      "          1       0.94      0.94      0.94       175\n",
      "\n",
      "avg / total       0.94      0.94      0.94       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))\n",
    "print ('\\n')\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</h6><b>OUR SCA IS TAKIING VERY REDUCED TIME OF 0.0098 AND PROVIDING ACCURACY OF 94%</b></h6>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
